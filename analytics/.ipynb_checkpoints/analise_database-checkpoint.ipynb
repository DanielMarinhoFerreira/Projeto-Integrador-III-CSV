{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mysql.connector import errorcode\n",
    "import mysql.connector as mysql\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import plotly.express as px\n",
    "from os import listdir \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração da conexão com o banco de dados\n",
    "config = {\n",
    "  'user': 'root',\n",
    "  'password': 'Database@2023',\n",
    "  'host': 'localhost',\n",
    "  'database': 'csgo'\n",
    "}\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "cnx = mysql.connect(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão com o banco de dados\n",
    "cnx = mysql.connect(**config)\n",
    "\n",
    "# Criação do cursor\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "# Consulta para selecionar todos os dados da tabela\n",
    "query_players = \"SELECT * FROM players\"\n",
    "query_picks = \"SELECT * FROM picks\"\n",
    "query_economy = \"SELECT * FROM economy\"\n",
    "query_results = \"SELECT * FROM results\"\n",
    "\n",
    "# Execução da consulta\n",
    "cursor.execute(query_players)\n",
    "\n",
    "# Obtenção dos resultados\n",
    "players = cursor.fetchall()\n",
    "\n",
    "# Obtenção dos nomes das colunas\n",
    "col_names_players = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Execução da consulta\n",
    "cursor.execute(query_picks)\n",
    "\n",
    "# Obtenção dos resultados\n",
    "picks = cursor.fetchall()\n",
    "\n",
    "# Obtenção dos nomes das colunas\n",
    "col_names_picks = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Execução da consulta\n",
    "cursor.execute(query_economy)\n",
    "\n",
    "# Obtenção dos resultados\n",
    "economy = cursor.fetchall()\n",
    "\n",
    "# Obtenção dos nomes das colunas\n",
    "col_names_economy = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Execução da consulta\n",
    "cursor.execute(query_results)\n",
    "\n",
    "# Obtenção dos resultados\n",
    "results = cursor.fetchall()\n",
    "\n",
    "# Obtenção dos nomes das colunas\n",
    "col_names_results = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Fechamento do cursor e da conexão\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão dos resultados em um DataFrame do Pandas\n",
    "df_players = pd.DataFrame(players, columns=col_names_players)\n",
    "df_picks = pd.DataFrame(picks, columns=col_names_picks)\n",
    "df_economy = pd.DataFrame(economy, columns=col_names_economy)\n",
    "df_results = pd.DataFrame(results, columns=col_names_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.info() #Verificar as informações sobre as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_results.isna().sum()) #Verificar a presença de valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mapa seja mais favorável para CT</h2>\n",
    "\n",
    "<p>Para analiar qual dos mapas é mais favoráveis para CT(Counter Terrorist), determinei essa característica calculando as pontuações médias obtidas em cada lado do mapas e, em seguida, comparando ambos os lados.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = ['Cache','Cobblestone','Dust2','Inferno','Mirage','Nuke','Overpass','Train','Vertigo']\n",
    "\n",
    "ct_1 = df_results[['Date_','_map','ct_1']].rename(columns={'ct_1':'ct'})\n",
    "ct_2 = df_results[['Date_','_map','ct_2']].rename(columns={'ct_2':'ct'})\n",
    "\n",
    "ct = pd.concat((ct_1, ct_2))\n",
    "\n",
    "t_1 = df_results[['Date_','_map','t_1']].rename(columns={'t_1':'t'})\n",
    "t_2 = df_results[['Date_','_map','t_2']].rename(columns={'t_2':'t'})\n",
    "\n",
    "t = pd.concat((t_1, t_2))\n",
    "\n",
    "t = t.sort_values('Date_')\n",
    "ct = ct.sort_values('Date_')\n",
    "\n",
    "series_t, series_ct, how_ct = {},{},{}\n",
    "\n",
    "for i, key in enumerate(maps):\n",
    "    t_map = t[t._map == maps[i]]\n",
    "    ct_map = ct[ct._map == maps[i]]\n",
    "    y_t = t_map.t.rolling(min_periods = 20, window= 200, center=True).sum().values\n",
    "    y_ct = ct_map.ct.rolling(min_periods = 20, window= 200, center=True).sum().values\n",
    "    \n",
    "    series_t[key] = pd.Series(data=y_t,index=t_map.Date_)\n",
    "    series_ct[key] = pd.Series(data=y_ct,index=ct_map.Date_)\n",
    "    \n",
    "    how_ct[key] = series_ct[key]/(series_ct[key]+series_t[key])//0.001/10\n",
    "    \n",
    "fig = go.Figure()\n",
    "\n",
    "for _map in maps:\n",
    "    fig.add_trace(go.Scatter(x=how_ct[_map].index, y=how_ct[_map].values, name=_map))\n",
    "    \n",
    "fig.add_trace(go.Scatter(x=['2015-11-01', '2020-03-12'], y=[50,50], mode='lines',line=dict(color='grey'),showlegend=False))\n",
    "fig.update_layout(title='Distribuição de rodadas entre os lados CT e T.', yaxis_title='Porcentagem de rodadas vencidas no lado CT (%)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Existem longos períodos sem dados para um mapa no gráfico. Isso ocorre porque os mapas são adicionados e removidos constantemente pelos administradores do jogo.\n",
    "\n",
    "observando os graficos o Nuke e Train oscilam como sendo os mapas mais favoráveis ao lado CT, tendo uma aprocimação de 57% das rodadas vencidas pelo lado CT, enquanto Dust2 e Cache são historicamente os mapas mais favoráveis ao lado T.</p>\n",
    "\n",
    "<img src=\"Comparação_mapas_Nuke_Train.png\">\n",
    "\n",
    "<p>interessante em 2019 no mês abril o mapa Vertigo entrou no jogo tendo somente 4 meses, após o Cache foi removido do jogo.</p>\n",
    "\n",
    "<img src=\"Comparação_mapas_Cache_Vertigo.png\">\n",
    "\n",
    "<p>É interessante observar que o Inferno era conhecido por ser um mapa fortemente favorável ao lado CT antes de 2016, o que foi uma das razões para sua atualização. Desde sua atualização, Inferno tem sido na verdade o mapa mais equilibrado nesse aspecto.</p>\n",
    "\n",
    "<img src=\"Comparação_mapas_Cache_Inferno.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sobre os mapas:</h1>\n",
    "\n",
    "<p>Mirage, Train, Inferno e Overpass são os mapas dos quais temos mais dados disponíveis. Eles também são os mapas presentes ao decorrer tempo;\n",
    "\n",
    "Cache, Cobblestone e Dust2 foram menos jogados, mas também estiveram fora por longos períodos de tempo:\n",
    "\n",
    "Vertigo tem dados limitados disponíveis, pois foi o mapa mais recentemente adicionado à pool de mapas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.groupby('_map').Date_.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>No CS:GO, os torneios mais respeitáveis são os Majors. Esses torneios são normalmente jogados duas vezes por ano e têm uma premiação de $1.000.000. Para a próxima analise, discretizar a coluna 'data' em um dataframe em uma coluna 'periodo_tempo'. Essa nova coluna se referirá ao torneio Major até 2019. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors = [{'tournament':'01. Cluj-Napoca 2015','start_date':'2015-10-28'},\n",
    "          {'tournament':'02. Columbus 2016','start_date':'2016-03-29'},\n",
    "          {'tournament':'03. Cologne 2016','start_date':'2016-07-05'},\n",
    "          {'tournament':'04. Atlanta 2017','start_date':'2017-01-22'},\n",
    "          {'tournament':'05. Krakow 2017','start_date':'2017-07-16'},\n",
    "          {'tournament':'06. Boston 2018','start_date':'2018-01-26'},\n",
    "          {'tournament':'07. London 2018','start_date':'2018-09-20'},\n",
    "          {'tournament':'08. Katowice 2019','start_date':'2019-02-28'},\n",
    "          {'tournament':'09. Berlin 2019','start_date':'2019-09-05'}]\n",
    "\n",
    "\n",
    "def create_col_time_period(df):\n",
    "    \n",
    "    list_ =  df.columns\n",
    "    for row in list_:\n",
    "        if row == 'time_period':\n",
    "            print('existe')\n",
    "        else:\n",
    "            df['time_period'] = None\n",
    "    \n",
    "    for major_start in majors:\n",
    "        df.loc[(df['Date_']>=major_start['start_date']), 'time_period'] = major_start['tournament']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = create_col_time_period(df_results)\n",
    "df_economy = create_col_time_period(df_economy)\n",
    "df_picks = create_col_time_period(df_picks)\n",
    "df_players = df_players.merge(df_results[['match_id','time_period']],'left',on='match_id')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_team_1 = df_results[['time_period','team_1','_map','ct_1','t_2','ct_2','t_1']\n",
    "                      ].rename(columns={'team_1':'team'})\n",
    "results_df_team_2 = df_results[['time_period','team_2','_map','ct_1','t_2','ct_2','t_1']\n",
    "                      ].rename(columns={'team_2':'team'})\n",
    "results_df_teams = pd.concat((results_df_team_1,results_df_team_2))[['time_period','team','_map']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = results_df_teams.groupby(['time_period','_map']).team.count()\n",
    "gb_text = round(gb*100/gb.groupby('time_period').sum(),1).reset_index().rename(columns={'team':'percentage'}) # type: ignore\n",
    "gb_text.percentage = gb_text.percentage.astype(str)+'%'\n",
    "gb = gb.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for _map in maps:\n",
    "    fig.add_bar(name=_map,x=gb[gb._map==_map].time_period,y=gb[gb._map==_map].team, # type: ignore\n",
    "                text=gb_text[gb_text._map==_map].percentage,textposition='inside') \n",
    "\n",
    "fig.update_layout(barmode='stack',legend=dict(traceorder='normal'),yaxis_title='Número de mapas jogados',font=dict(size=10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como mencionado anteriormente, Nuke é historicamente o mapa menos popular do pool. Isso vem mudando recentemente, já que equipes que costumavam banir permanentemente o mapa passaram a banir mapas como Vertigo. Vertigo, como o mapa mais novo e não convencional, também é o mapa mais impopular, provavelmente devido às muitas mudanças que teve em seu curto período competitivo.</p>\n",
    "<img src=\"ban_de_mapas.png\">\n",
    "\n",
    "<p>O período entre Columbus e Cologne 2016 teve a menor quantidade de mapas jogados e também foi o mais curto (menos de 4 meses), enquanto o período entre Boston e London 2018 teve a maior quantidade de mapas jogados e também foi o mais longo (mais de 7 meses).</p>\n",
    "<img src=\"mapas.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_team_1_ct = results_df_team_1.rename(columns={'ct_1':'ct_team','t_2':'t_opponent'}).drop(columns=['ct_2','t_1'])\n",
    "results_df_team_2_ct = results_df_team_2.rename(columns={'ct_2':'ct_team','t_1':'t_opponent'}).drop(columns=['ct_1','t_2'])\n",
    "results_df_ct = pd.concat((results_df_team_1_ct,results_df_team_2_ct),sort=True)\n",
    "\n",
    "\n",
    "results_df_team_1_t = results_df_team_1.rename(columns={'t_1':'t_team','ct_2':'ct_opponent'}).drop(columns=['ct_1','t_2'])\n",
    "results_df_team_2_t = results_df_team_2.rename(columns={'t_2':'t_team','ct_1':'ct_opponent'}).drop(columns=['ct_2','t_1'])\n",
    "results_df_t = pd.concat((results_df_team_1_t,results_df_team_2_t),sort=True)\n",
    "\n",
    "results_df_ct['side_diff'] = results_df_ct['ct_team']- results_df_ct['t_opponent']\n",
    "results_df_ct['side_sum'] = results_df_ct['ct_team']+results_df_ct['t_opponent']\n",
    "\n",
    "results_df_t['side_diff'] = results_df_t['t_team']-results_df_t['ct_opponent']\n",
    "results_df_t['side_sum']  = results_df_t['t_team'] +results_df_t['ct_opponent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_time_map_team(results_df_side):\n",
    "    gb = results_df_side.groupby(['time_period','_map','team'])[['side_diff','side_sum']].sum()\n",
    "    gb['side_diff_per_game'] = gb['side_diff']/(gb['side_sum']/15)\n",
    "    gb = gb.sort_values(['time_period','_map','side_diff_per_game'],ascending=[1,1,0])\n",
    "\n",
    "    for major in majors:\n",
    "        col = major['tournament']\n",
    "        _filter = (gb.side_sum > gb.loc[col].side_sum.mean()*3/4)\n",
    "        gb.loc[col] = gb.loc[_filter][gb.loc[_filter].index.get_level_values(0)==col]\n",
    "\n",
    "    gb.dropna(inplace=True)    \n",
    "\n",
    "    return gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_ct = groupby_time_map_team(results_df_ct)\n",
    "gb_t = groupby_time_map_team(results_df_t)\n",
    "\n",
    "new_data_ct = pd.DataFrame(data=results_df_ct)\n",
    "new_data_ct.reset_index()\n",
    "display(new_data_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>classificar as melhores equipes em cada mapa e em cada lado (CT e T) para cada período de tempo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranking_teams_sides(gb):\n",
    "    rankings_teams = {}\n",
    "    for _map in maps:\n",
    "        rankings_teams[_map] = pd.DataFrame(index=range(1,6),)\n",
    "        rankings_teams[_map].index.name = 'ranking'\n",
    "        rankings_teams[_map].style.set_caption(_map)\n",
    "\n",
    "        for major in majors:\n",
    "            col = major['tournament']\n",
    "            try:\n",
    "                rankings_teams[_map][col] = gb.loc[col,_map]['side_diff_per_game'][:5].index\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        print('\\n'+_map+':')\n",
    "        display(rankings_teams[_map])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(new_data_ct[['ct_team', 't_opponent', 'side_diff','side_sum']])\n",
    "ax.set_ylabel('')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "df_no_ = new_data_ct[['time_period','_map','team']]\n",
    "\n",
    "df_cat = df_no_.apply(LabelEncoder().fit_transform) # type: ignore #substitui as colunas originais pelas colunas codificadas\n",
    "\n",
    "new_data_ct[['time_period','_map','team']] = df_cat # alterando as colunas originais pelas conulas codificadas\n",
    "display(new_data_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Separar os atributos preditores (X) do alvo (y)\n",
    "X = new_data_ct.drop('side_sum', axis=1)\n",
    "y = new_data_ct['side_sum']\n",
    "\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(X[['_map','ct_team','t_opponent','team','time_period','side_diff']])\n",
    "enc.transform(X[['_map','ct_team','t_opponent','team','time_period','side_diff']])\n",
    "\n",
    "\n",
    "# Dividir o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Padronizar as variáveis preditoras\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Treinar um modelo de Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste usando o modelo de Naive Bayes\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Fazer as previsões nos dados de teste\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do  modelo de Naive Bayes\n",
    "print('Acurácia:', accuracy_score(y_test, y_pred))\n",
    "print('Matriz de confusão:')\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('T-side Rankings:\\n')\n",
    "plot_ranking_teams_sides(gb_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CT-side Rankings:\\n')\n",
    "plot_ranking_teams_sides(gb_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
